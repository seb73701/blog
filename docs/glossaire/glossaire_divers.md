---
title: Glossaire divers
description: 
published: true
date: 2023-04-21T10:37:31.458Z
tags: 
editor: markdown
dateCreated: 2023-04-21T10:37:27.407Z
---

===== A =====

**Algorithm**: A set of rules given to an AI, neural network, or other machines to help it learn on its own; classification, clustering, recommendation, and regression are four of the most popular types.

**Apache Flink**: An open-source streaming data processing framework. It is written in Java and Scala and is used as a distributed streaming dataflow engine.

**Apache Hadoop**: An open-source tool to process and store large distributed data sets across machines by using MapReduce.

**Apache Kafka**: A distributed streaming platform that improves upon traditional message brokers through improved throughput, built-in partitioning, replication, latency, and reliability.

**Apache NiFi**: An open-source Java server that enables the automation of data flows between systems in an extensible, pluggable, open manner. NiFi was open-sourced by the NSA.

**Apache Spark**: An open-source big data processing engine that runs on top of Apache Hadoop, Mesos, or the cloud.

**Artificial intelligence**: A machine's ability to make decisions and perform tasks that simulate human intelligence and behavior.

**Artificial neural network (ANN)**: A learning model created to act like a human brain that solves tasks that are too difficult for traditional computer systems to solve.

**Autonomic computing**: A system's capacity for adaptive self-management of its own resources for high-level computing functions without user input.

**Agent**: A program installed on specific physical servers in order to handle the execution of various processes on that server.

**Agile software development**: A software development methodology and philosophy, focused on user feedback, software quality, and the ability to respond quickly to changes and new product requirements.

**Artifact**: Any description of a process used to create a piece of software that can be referred to, including diagrams, user requirements, and UML models.

**Application release automation (ARA)**: The process of packaging and deploying software from development to production, where software is moved through different environments and releases are coordinated automatically.

**Autonomy**: The ability to make changes with the resources currently available, without the need to defer to something or someone higher up in the hierarchy.

**Application Security (AppSec)**: An IT field where specialists focus on secure application design and are familiar with programming.

**Authentication**: A mechanism that confirms a user’s identity when they are requesting access to a resource in a system. This is generally handled by granting users an access token when they confirm their identity through a mechanism such as a password.

**Automated Remediation**: Automatic action taken as a result of insights into how an application is operating.

**Agile**: An iterative approach to development where the team delivers bits of software in frequent, rapid cycles. It’s not a concrete method, but rather a set of principles described in the Agile Manifesto in 2001.

**Agile Release Train (ART)** : While the term may sound confusing, what it really means is “a team of teams.” ARTs are used in the SAFe framework where groups of teams stick together over a long period of time to deliver work at the Program level.

----
===== B =====

**Big data**: A common term for large amounts of data. To be qualified as big data, data must be coming into the system at a high velocity, with large variation, or at high volumes.

**Blob storage**: An Azure service that stores unstructured data in the cloud as a blob or an object.

**Business intelligence**: The process of visualizing and analyzing business data for the purpose of making actionable and informed decisions.

**Behavior-driven development (BDD)**: An evolution of test-driven development that focuses on collaboration between development and business stakeholders to define user stories that determine the development of the application using a human-readable DSL.

**Branching**: The duplication of an object under review in source control so that the same code can be modified by more than one developer in parallel.

**Build artifact**: The resulting application or object created by a build process. Typically this involves source code being compiled into a runtime artifact. In the Java ecosystem, this involves Java source code being compiled into a JAR or WAR file.

**Bitcoin**: A digital currency (cryptocurrency) that is not ruled by any governing body.

**Blockchain**: Essentially, a very big database of transactions, also known as a transaction ledger.

**Backlog** : An unordered list of to-do items for the projects. The backlog provides a pool of tasks out of which you pick work items for the nearest Sprint during the Sprint planning event.

**Burndown Chart** : A diagram that shows work left to do versus time. It has the “Ideal burndown,” aka “Ideal remaining work” line, against which you can measure actual progress.

{{:glossaire:sample-burndown-chart-min.png?200|}}

----
===== C =====

**Cluster**: A subset of data that share particular characteristics. Can also refer to several machines that work together to solve a single problem.

**COAP**: Constrained Application Protocol is an Internet Application protocol for limited resource devices that can be translated to HTTP if needed.

**Chatbots**: A chat robot (chatbot for short) that is designed to simulate a conversation with human users by communicating through text chats, voice commands, or both. They are a commonly used interface for computer programs that include AI capabilities.

**Classification**: Classification algorithms let machines assign a category to a data point based on training data.

**Cluster analysis**: A type of unsupervised learning used for exploratory data analysis to find hidden patterns or grouping in data; clusters are modeled with a measure of similarity defined by metrics such as Euclidean or probabilistic distance.

**Clustering**: Clustering algorithms let machines group data points or items into groups with similar characteristics.

**Cognitive computing**: A computerized model that mimics the way the human brain thinks. It involves self-learning through the use of data mining, natural language processing, and pattern recognition.

**Convolutional neural network (CNN)**: A type of neural networks that identifies and makes sense of images.

**Capacity test**: A test that is used to determine the maximum number of users a computer, server, or application can support just before failing.

**Commit**: A way to record the changes to a repository and add a log message to describe the changes that were made.

**Complex-adaptive systems**: Any system made of a collection of similar, smaller pieces that are dynamically connected and can change to adapt to changes for the benefit of a macrostructure.

**Configuration drift**: How software and hardware configurations become inconsistent with the master version due to manual and ad hoc changes (like hotfixes) that are not committed back to version control. Often a significant source of technical debt.

**Containers**: Resource isolation at the OS (rather than machine) level, usually (in UNIX-based systems) in user space. Isolated elements vary by containerization strategy and often include file system, disk quota, CPU and memory, I/O rate, root privileges, and network access. Much lighter-weight than machine-level virtualization and sufficient for many isolation requirement sets.

**Continuous delivery (CD)**: A software engineering approach in which continuous integration, automated testing, and automated deployment capabilities allow software to be developed and deployed rapidly, reliably, and repeatedly with minimal human intervention.

**Continuous deployment**: A software development practice in which every code change goes through the entire pipeline and is put into production automatically, resulting in many production deployments every day. It does everything that Continuous Delivery does, but the process is fully automated, and there’s no human intervention at all.

**Continuous integration (CI)**: A software development process where a branch of source code is rebuilt every time code is committed to the source control system. The process is often extended to include deployment, installation, and testing of applications in production environments.

**Continuous quality**: The principle that preaches the continuous quest for quality across the entire SDLC, starting from requirements definition, code development, testing, and operations. Another key area of focus for Continuous Quality is the application code pipeline orchestration. There are many opportunities to negatively impact the quality of an application when code is being manually moved across environments.

**Continuous testing**: The process of executing unattended automated tests as part of the software delivery pipeline across all environments to obtain immediate feedback on the quality of a code build.

**Cloud Access Security Brokers (CASB)**: A type of software that provides security policy enforcement between cloud service consumers and providers, consolidating features such as encryption, auditing, DLP, access control, and anomaly detection.

**Content Delivery Network (CDN)**: A hosted, geographically-distributed server network that improves website file delivery and performance. It can also include security features such as DDoS protection.

**Cross-Site Request Forgery (CSRF)**: A malicious web exploit in which an attacking program forces a user’s browser to perform an unwanted action on a site where the user is currently authenticated.

**Cross-Site Scripting (XSS)**: A type of injection attack that targets an application through client-side scripts, which will usually be JavaScript.

**Cryptocurrency**: An encrypted digital exchange whose encryption techniques are used as a method to ensure that secure transactions take place that are both regulated and verified.

----
===== D =====

**Data engineering**: The collection, storage, and processing of data so that it can be queried by a data scientist.

**Data flow management**: The specialized process of ingesting raw device data, while managing the flow of thousands of producers and consumers. Then performing basic data enrichment, analysis in stream, aggregation, splitting, schema translation, format conversion, and other initial steps to prepare the data for further business processing.

**Data governance**: The process of managing the availability, usability, integrity, and security of data within a data lake.

**Data integration**: The process of combining data from different sources and providing a unified view for the user.

**Data lake**: A storage repository that holds raw data in its native format.

**Data mining**: A practice to generate new information through the process of examining and analyzing large databases. 

**Data operationalization**: The process of strictly defining variables into measurable factors.

**Data preparation**: The process of collecting, cleaning, and consolidating data into one file or data table, primarily for use in analysis.

**Data processing**: The process of retrieving, transforming, analyzing, or classifying information by a machine.

**Data science**: A field that explores repeatable processes and methods to derive insights from data.

**Data swamp**: What a data lake becomes without proper governance.

**Data validation**: The act of examining data sets to ensure that all data is clean, correct, and useful before it is processed.

**Data warehouse**: A large collection of data from various sources used to help companies make informed decisions.

**Device layer**: The entire range of sensors, actuators, smartphones, gateways, and industrial equipment that send data streams corresponding to their environment and performance characteristics.

**Decision tree**: A tree and branch-based model used to map decisions and their possible consequences, similar to a flow chart.

**Deep learning**: The ability for machines to autonomously mimic human thought patterns through artificial neural networks composed of cascading layers of information.

**Deployment pipeline**: A deployment pipeline is an automated manifestation of your process for getting software from version control into the hands of your users.

**DevOps**: An IT organizational methodology where all teams in the organization, especially development teams and operations teams, collaborate on both development and deployment of software to increase software production agility and achieve business goals.

**DevSecOps**: Integrating security as an integral part of the DevOps methodology.

**Data Exfiltration**: An unauthorized transfer of data. It can be carried out manually or through a malicious automated program.

**Decentralized Autonomous Organization (DAO)**: An organization that serves as a form of a venture capital fund. It runs through smart contracts and its transaction records are maintained in a blockchain.

**Distributed Denial of Service Attack (DDOS)**: A type of attack that shuts down services, usually by sending a number of requests to the service that the service cannot handle, interrupting legitimate requests of the service.

**Dynamic Applications Security Testing (DAST)**: An analysis of an application’s security that only monitors the runtime environment and the code that is executed in it. It simulates potential attacks and analyzes the results.

**Daily Scrum** : A daily meeting practiced in the Scrum project management framework. At this meeting, each person on the Scrum team briefly answers three questions: “What did you do yesterday?” “What will you do today?” and “Are there any obstacles?”

**Definition of Done (DoD)** : A concise list of criteria a feature must meet to be ticked off as done. This often includes the activities that must be completed for a piece of functionality to be marked as “potentially shippable.”

----
===== E =====
**Event-driven architecture**: A software architecture pattern where events or messages are produced by the system, and the system is built to react, consume, and detect other events.

**Encryption**: A method for encoding data so that it is unreadable to parties without a method for decryption.

**Exploit**: A piece of code that takes advantage of a vulnerability in computer software or hardware in order to produce undesirable behavior.

**Extreme Programming (XP)** : A set of programming practices—TDD, pair programming, continuous integration, collective code ownership, etc.—popularised by Kent Beck. XP takes certain programming techniques to an extreme to maximize their effectiveness.

----
===== F =====
**Fluent**: A type of condition that can change over time.

**Fail fast**: A strategy in which you try something, it fails, feedback is delivered quickly, you adapt accordingly, and try again.

**Feedback loop**: Input on usability and user experience back to the developer.

**Fuzz Testing (Fuzzing)**: An automated method for injecting malformed data in order to find vulnerabilities in an application.

**Framework** : A process template according to which a project is run. A framework prescribes project stages, organization units, sequence of actions, practices, etc. Popular PM frameworks include Scrum, Kanban, Extreme Programming (XP), and others.

**Functional analysis** : A method of estimating a software project. In functional analysis, the project is broken into features, and each feature is assigned a particular number of functional points to indicate its difficulty.

----

===== G =====

**GPU-accelerated databases**: Databases which are required to ingest streaming data.

**Graph analytics**: A way to organize and visualize relationships between different data points in a set.

**Game AI**: A form of AI specific to gaming that uses an algorithm to replace randomness. It is a computational behavior used in non-player characters to generate human-like intelligence and reaction-based actions taken by the player.

**Genetic algorithm**: An evolutionary algorithm based on principles of genetics and natural selection that is used to find optimal or near-optimal solutions to difficult problems that would otherwise take decades to solve.

----
===== H =====

**Hadoop**: A programming framework for processing and storing big data, particularly in distributed computing environments.

**Heuristic search techniques**: Support that narrows down the search for optimal solutions for a problem by eliminating options that are incorrect.

----
===== I =====

**Ingestion**: The intake of streaming data from any number of different sources.

**Integration testing**: Testing that occurs after unit testing, but before validation testing, where individual software components are combined and tested as a single group to ensure they work as a whole.

**Iterations**: Releases of applications or code. Faster iterations/releases results in faster feedback for the developer, increased quality, and speed to market.

**Identity Management**: A method for defining the abilities and resource accessibility that users have when they are authenticated in a system.

**Information Security (InfoSec)**: An IT field where specialists are skilled security generalists, and in larger companies they are CISOs and managers.

**Injection Attack**: A scenario where attackers relay malicious code through an application to another system for malicious manipulation of the application. These attacks can target an operating system via system calls, external programs via shell commands, or databases via query language (SQL) injection.

**Interactive Application Security Testing (IAST)**: A combination of SAST and DAST that is usually implemented in the form of an agent that monitors attacks and identifies vulnerabilities within the test runtime environment.

**IT Security (ITSec)**: An IT field where specialists focus on system administration security (i.e. in the host, auth servers, mandatory access controls systems, etc.).

----
===== K =====
**Knowledge engineering**: Focuses on building knowledge-based systems, including all of the scientific, technical, and social aspects of it.

**Kanban** ; An Agile framework used in software project management. In Japanese, “kanban” means “visible board/poster.” The framework places importance on visualizing the workflow, making everyone’s work transparent, and disseminating information, among other things.

{{:glossaire:kanban-board-min.png?200|}}

----
===== L =====
**Logic programming**: A type of programming paradigm in which computation is carried out based on the knowledge repository of facts and rules; LISP and Prolog are two logic programming languages used for AI programming.

**Lead time**: The time it takes to move work in progress (WIP) to a finished state in a manufacturing plant. In software development, this is represented by moving code changes to production.

**Lean** : An approach to software development popularized by Mary and Tom Poppendieck in their book Lean Software Development. It propagates starting small, releasing a Minimum Viable Product (MVP) as early as possible, and adding features to it as you go.

----
===== M =====

**MapReduce**: A data processing model that filters and sorts data in the Map stage, then performs a function on that data and returns an output in the Reduce stage.

**Munging**: The process of manually converting or mapping data from one raw form into another format for more convenient consumption.

**Machine intelligence**: An umbrella term that encompasses machine learning, deep learning, and classical learning algorithms.

**Machine learning**:  A facet of AI that focuses on algorithms, allowing machines to learn without being programmed and change when exposed to new data. 

**Machine perception**: The ability for a system to receive and interpret data from the outside world similarly to how humans use our senses. This is typically done with attached hardware, though software is also usable.

**Microservices architecture**: The practice of developing software as an interconnected system of several independent, modular services that communicate with each other.

**Model-based testing**: A software testing technique in which the test cases are derived from a model that describes the functional aspects of the System Under Test (SUT). Visual models can be used to represent the desired behavior of a SUT, or to represent testing strategies and a test environment. From that model manual tests, test data, and automated tests can be generated automatically.

**Miners**: Calculate the Proof-Of-Work hash of all transactions in a blockchain block, in essence sealing the new block and then transmitting it to the network so that all nodes know a new block has been produced.

----
===== N =====

**Normal distribution**: A common graph representing the probability of a large number of random variables, where those variables approach normalcy as the data set increases in size. Also called a Gaussian distribution or bell curve.

**Normalizing**: The process of organizing data into tables so that the results of using the database are always unambiguous and as intended.

**Natural language processing**: The ability for a program to recognize human communication as it is meant to be understood. 

**Network Security (NetSec)**: An IT field where specialists focus on the security of data as it flows through network routers (i.e. firewalls, IDS, VPNs, application-specific protocols, etc.).

----
===== O =====
**One-stop shop/out-of-the-box tools**: Tools that provide a set of functionalities that works immediately after installation with hardly any configuration or modification needs. When applied to the software delivery, a one-stop shop solution allows quick setup of a deployment pipeline.

**Orchestration**: The method to automate the management and deployment of your applications and containers.

**Open Web Application Security Project (OWASP)**: An online community of corporations, educational organizations, and individuals focused on providing web security tools, resources, events, and more for the wider development community.

----
===== P =====

**Parse**: To divide data, such as a string, into smaller parts for analysis.

**Persistent storage**: A non-changing place, such as a disk, where data is saved after the process that created it has ended.

**Python**: A general-purpose programming language that emphasizes code readability in order to allow programmers to use fewer lines of code to express their concepts.

**Pair-programming**: A software development practice where two developers work on a feature, rather than one, so that both developers can review each others’ code as it’s being written in order to improve code quality.

**Production**: The final stage in a deployment pipeline where the software will be used by the intended audience.

**Penetration Testing (Pen Testing)**: A technique to find vulnerabilities in a computer system by attacking that system through various methods that a real attacker would use.

**Protocol Exploitation**: A security vulnerability that disrupts the interactions between multiple communication protocols.

**Portfolio** - The highest management level in Scaled Agile Framework (SAFe). At the portfolio level, you get a birds-eye view of all projects in an organization. That is where you manage the people and practices needed for the completion your strategic business goals. Lower organizational levels are Program (smaller than Portfolio) and Team (smaller than Program).

**PRINCE2** - Stands for PRojects IN Controlled Environments, version two. It's a project management method initially developed as a UK Government standard for managing information systems projects. PRINCE2 divides a project into controllable stages and provides guidance (and doc templates) on how each process should be managed. The method is generally used for high-level management and can be combined with other Agile frameworks like Scrum.

**Product Increment** : A piece of functionality or a product feature delivered at the end of an Agile cycle. Usually, it’s a deliverable shipped at the end of each sprint in Scrum.

**Product Owner** : A person who has a holistic view of the product. A Product Owner focuses on product features as they’re perceived by the end user, while a Project Manager is more concerned with the technical implementations of those features.

**Product Sponsor** : A member of the C-Suite (a senior exec) who communicates strategic goals to the Agile team. This is done to ensure the development team stays informed about the latest business status of the project. Not a full-time job.

**Project Management Office** : A department responsible for storing and disseminating project management expertise in an organization. It is a source of valuable PM knowledge, documentation, standards, KPIs, and other helpful information.

**Project Manager** : A person who manages the team and serves as an intermediary between the team and the client/stakeholders. The PM plans and oversees project execution while also communicating with the party sponsoring the project on a regular basis.

----
===== R =====

**R**: An open-source language primarily used for data visualization and predictive analytics.

**Real-time stream processing**: A model for analyzing sequences of data by using machines in parallel, though with reduced functionality.

**Relational database management system (RDBMS)**: A system that manages, captures, and analyzes data that is grouped based on shared attributes called relations.

**Resilient distributed dataset**: The primary way that Apache Spark abstracts data, where data is stored across multiple machines in a fault-tolerant way.

**Recurrent neural network (RNN)**: A type of neural network that makes sense of sequential information and recognizes patterns, and creates outputs based on those calculations.

**Runtime Application Self-Protection (RASP)**: A feature that is built into an application in order to detect and halt attacks in real-time, automatically.

**Reetrancy Attacks**: An attack where untrusted code reenters a contract and manipulates state.

**Retrospective** : A meeting held at the end of each Sprint in the Scrum framework. During a Sprint retrospective organized by the Scrum Master, participants discuss the Sprint in an open, no-blame-placed conversation. The purpose is to learn from experience and to improve continuously.

----
===== S =====

**Shard**: An individual partition of a database.

**Smart data**: Digital information that is formatted so it can be acted upon at the collection point before being sent to a downstream analytics platform for further data consolidation and analytics.

**Stream processing**: The real-time processing of data. The data is processed continuously, concurrently, and record-by-record.

**Structured data**: Information with a high degree of organization.

**Supervised learning**: A type of machine learning in which output datasets train the machine to generate the desired algorithms, like a teacher supervising a student; more common than unsupervised learning.

**Swarm behavior**: From the perspective of the mathematical modeler, it is an emergent behavior arising from simple rules that are followed by individuals and does not involve any central coordination.

**Shift left**: Introducing automated testing into the SDLC from inception.

**Source control**: A system for storing, tracking, and managing changes to software. This is commonly done through a process of creating branches (copies for safely creating new features) off of the stable master version of the software and then merging stable feature branches back into the master version. This is also known as version control or revision control.

**Staging environment**: Used to test the newer version of your software before it’s moved to live production. Staging is meant to replicate as much of your live production environment as possible, giving you the best chance to catch any bugs before you release your software.

**Single Sign-On**: A user or session authentication process that allows a user to enter one set of credentials in order to access multiple applications that are connected by the SSO software.

**Smart Contracts**: A computerized transaction protocol that executes the terms of a contract.

**Static Application Security Testing (SAST)**: An analysis of an application’s security that looks at an application’s source code, bytecode, or binary code to determine if there are parts that could allow security exploits by attackers.

**Scaled Agile** : Traditional Agile approach, adjusted to suit a large organization. In scaled Agile frameworks, one finds larger organizational units (for instance, “a team of teams”) and additional practices that help manage a bigger crowd of people and a more complex set of dependencies.

**SAFe (Scaled Agile Framework)** : One of the most popular Scaled Agile frameworks. SAFe provides guidance as to how to plan and organize work at the Portfolio, Program, and Team level.

**Scope Creep** : A project’s work scope is described in the Vision and Scope document. When unexpected changes are made to the scope, this can lead to “scope creep” and eventually delay the project.

**Scrum** : By far the most popular and widely used Agile framework. In Scrum, work is done in short iterations known as Sprints. The Scrum team is cross-functional and self-organizing (where no one is the boss), and the Scrum Master simply serves to facilitate the framework’s implementation.

**Scrum Master** : A person whose job is to ensure the team follows Scrum. The Scrum Master should also remove any impediments that hamper the Scrum process (a lack of information, unresolved dependencies, etc.).

**Scrum Team** : A cross-functional team of usually up to 9 people. May consist of a business analyst, a designer, a developer, a Scrum Master, a QA, etc. Scrum teams are normally self-organizing; that is, nobody is telling anyone what to do.

**Six Sigma** : A statistical analysis-based method of plotting defects to identify development process weaknesses and areas that can be optimized.

**Sprint** : A two-week work period during which the team works to deliver a product increment in Scrum. Is preceded by a planning event and is followed by a retrospective meeting.

----
===== T =====

**Taxonomy**: The classification of data according to a pre-determined system with the resulting catalog used to provide a conceptual framework for easy access and retrieval.

**Telemetry**: The remote acquisition of information about an object (for example, from an automobile, smartphone, medical device, or IoT device).

**Transformation**: The conversion of data from one format to another.

**Technical debt**: A concept in programming that reflects the extra development work that arises when code that is easy to implement in the short run is used instead of applying the best overall solution.

**Test Automation**: The use of special software (separate from the software being tested) to control the execution of tests and the comparison of actual outcomes with predicted outcomes.

**Turing Complete**: A system theoretically capable of solving any computational problem if memory or runtime limitations are not taken into consideration.

**Test-Driven Development (TDD)** : An Extreme Programming practice. Before turning a software requirement into code, a programmer writes an automated test for it first. This is done to increase testability and maintainability of the code written.

**Time and Material** : A concept used to estimate software project costs. In a time-and-material contract, one pays contractors by the hour (or another time period) and may compensate additional costs.

----
===== U =====

**Unstructured data**: Data that either does not have a pre-defined data model or is not organized in a pre-defined manner.

**Unsupervised learning**: A type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. The most common unsupervised learning method is cluster analysis.

**Unit testing**: A testing strategy in which the smallest unit of testable code is isolated from the rest of the software and tested to determine if it functions properly.

**User acceptance test**: The final phase of software testing where clients and end users determine whether the program will work for the end-user in real world scenarios. This stage is also known as beta testing.

**User Story** : A way of writing a requirement to the product. It’s written in the following format: “As a [Role], I want the software to [do this and this], so that [this and this result is achieved].” For example: “As a blogger, I want to be able to schedule a blog post so that it is published at some point in the future.”

----
===== V =====

**Visualization**: The process of analyzing data and expressing it in a readable, graphical format, such as a chart or graph.

**Vision and Scope** : The Vision and Scope document is normally created early in the development cycle. It describes product vision, economical justification, users, stakeholders, features, the scope of work required to implement initial features, and related information.

----
===== W =====

**Web Application Firewall (WAF)**: An HTTP/S firewall for web applications; legacy WAFs can create network architecture complexity and aren’t very accurate.

**Waterfall** : The traditional Waterfall methodology consists in careful planning, stage-based approach and delivering the full product at the finish line. A Waterfall project goes through gradual (not concurrent) stages, such as planning, development, testing, and launch to production.

**Work Breakdown Structure (WBS)** : A document that contains a structured list of program components (at the highest level) and major/minor features, as well as their descriptions and effort estimates. A WBS document is filled out by different people assigned to a project (a BA, a developer, a QA) and each enters the amount of effort required for each listed feature.

{{:glossaire:wbs-example-min.png?200|}}

----
===== Z =====

**Zones**: Distinct areas within a data lake that serve specific, well-defined purposes.

**Zero Day**: A vulnerability that is currently unknown to the software maker or to antivirus vendors. It also refers a piece of code that allows attackers to exploit a zero day vulnerability